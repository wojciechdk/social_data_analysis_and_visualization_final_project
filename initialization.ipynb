{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border:2px solid black\"> </p>\n",
    "<span style=\"font-family:Lucida Bright;\">\n",
    "<p style=\"margin-bottom:1cm\"></p>\n",
    "<center>\n",
    "<font size=\"7\"><b>Social Data Analysis and Visualization</b></font>\n",
    "<p style=\"margin-bottom:1cm\"></p>\n",
    "<font size=\"3\"><b>Final Project</b></font>\n",
    "<p style=\"margin-bottom:1cm\"></p>\n",
    "<font size=\"6\"><b>Demographics of Copenhagen</b></font>\n",
    "<p style=\"margin-bottom:0.8cm\"></p>\n",
    "<font size=\"3\"><b>Wojciech Mazurkiewicz, DTU, 14 May 2021</b></font>\n",
    "<p style=\"margin-bottom:1.5cm\"></p>\n",
    "<font size=\"6\"><b>Initialization</b></font>\n",
    "<br>\n",
    "<font size=\"3\"><b></b></font>\n",
    "</center>\n",
    "<p style=\"margin-bottom:0.7cm\"></p>\n",
    "<p style=\"border:2px solid black\"> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#How-to-read-this-notebook\" data-toc-modified-id=\"How-to-read-this-notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>How to read this notebook</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configuration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notebook-options\" data-toc-modified-id=\"Notebook-options-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Notebook options</a></span></li><li><span><a href=\"#Bokeh-options\" data-toc-modified-id=\"Bokeh-options-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Bokeh options</a></span></li><li><span><a href=\"#Matplotlib-options\" data-toc-modified-id=\"Matplotlib-options-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Matplotlib options</a></span></li><li><span><a href=\"#Pandas-options\" data-toc-modified-id=\"Pandas-options-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Pandas options</a></span></li><li><span><a href=\"#Warnings\" data-toc-modified-id=\"Warnings-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Warnings</a></span></li></ul></li><li><span><a href=\"#Paths\" data-toc-modified-id=\"Paths-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Paths</a></span></li><li><span><a href=\"#Function-definitions\" data-toc-modified-id=\"Function-definitions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Function definitions</a></span><ul class=\"toc-item\"><li><span><a href=\"#General-functions\" data-toc-modified-id=\"General-functions-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>General functions</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Plotting-functions\" data-toc-modified-id=\"Plotting-functions-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Plotting functions</a></span></li><li><span><a href=\"#Dataframe-functions\" data-toc-modified-id=\"Dataframe-functions-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Dataframe functions</a></span></li><li><span><a href=\"#Data-cleaning-functions\" data-toc-modified-id=\"Data-cleaning-functions-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Data cleaning functions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read this notebook\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the pre-rendered outputs will first display properly when the notebook is __trusted__.\n",
    "\n",
    "If you are viewing the HTML-version of the notebook and would like to download the .ipynm file, you can do it [here](https://social-data-analysis-and-visualization-final-project.s3.eu-central-1.amazonaws.com/initialization.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains everything necessary to run all the other notebooks in this projects, including imports, configuration, paths, and function definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:10:57.839408Z",
     "start_time": "2021-05-09T20:10:57.816474Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bplt\n",
    "import calendar\n",
    "import datetime\n",
    "import folium\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import warnings\n",
    "\n",
    "from bokeh.io import output_file\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.models import Legend\n",
    "from bokeh.models.ranges import FactorRange\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "\n",
    "from folium.map import FeatureGroup\n",
    "from folium.plugins import HeatMap, HeatMapWithTime\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.image import NonUniformImage\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Configuration\n",
    "<hr style=\"border:2px solid black\"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:37.886303Z",
     "start_time": "2021-05-09T20:09:37.881311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decide which output is shown below the cells.\n",
    "InteractiveShell.ast_node_interactivity = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bokeh options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:37.945646Z",
     "start_time": "2021-05-09T20:09:37.890287Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show bokeh figures in the notebook.\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:38.018461Z",
     "start_time": "2021-05-09T20:09:37.950634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show matplotlib plots inline.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:38:55.231661Z",
     "start_time": "2021-05-10T17:38:55.174815Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c43ba651e0b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define the format in which the numbers will be shown in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the pandas dataframes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:,.1f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Decide how to handle the \"SettingWithCopyWarning\" warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the format in which the numbers will be shown in\n",
    "# the pandas dataframes.\n",
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "\n",
    "# Decide how to handle the \"SettingWithCopyWarning\" warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Set the maximum number of rows and columns to show when \n",
    "# displaying a Pandas dataframe.\n",
    "pd.options.display.max_rows = 75\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:12:46.352925Z",
     "start_time": "2021-05-09T20:12:46.345936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decide how to handle warnings.\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:17:40.280949Z",
     "start_time": "2021-05-09T20:17:40.273966Z"
    },
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Project root.\n",
    "path_root = Path(\n",
    "    r'C:\\GDrive\\DTU\\Kurser\\Social_Data_Analysis_and_Visualization_02806\\final_project')\n",
    "\n",
    "# Resources root.\n",
    "path_resources_root = path_root / 'resources'\n",
    "\n",
    "# Data folders.\n",
    "path_data_root = path_resources_root / 'data'\n",
    "path_data_citizenship_root = path_data_root / 'citizenship'\n",
    "path_data_dwellings_root = path_data_root / 'dwellings'\n",
    "path_data_geo_root = path_data_root / 'geo'\n",
    "path_data_marital_status_root = path_data_root / 'marital_status'\n",
    "path_data_without_district_info_root = path_data_root / 'without_district_information'\n",
    "path_data_clean_root = path_data_root / 'clean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:38.757991Z",
     "start_time": "2021-05-09T20:09:34.620Z"
    },
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "# A function that returns a dict of object attributes.\n",
    "def get_obj_attributes(obj):\n",
    "    return {attribute_name: getattr(obj, attribute_name)\n",
    "            for attribute_name in dir(obj)\n",
    "            if (not attribute_name.startswith('__')\n",
    "                and not callable(getattr(obj, attribute_name)))}\n",
    "\n",
    "# A function that will print a markdown text.\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "# A function that returns unique values from a text.\n",
    "def unique(list_):\n",
    "    return list(set(list_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:38.759992Z",
     "start_time": "2021-05-09T20:09:34.624Z"
    },
    "code_folding": [
     81
    ]
   },
   "outputs": [],
   "source": [
    "# Define a class th\n",
    "class CphData:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Country of origin (no distric info)\n",
    "        df_country_of_origin = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_population_by_country_of_origin_without_district.pkl')\n",
    "        df_country_of_origin.attrs = {'name': 'Country of origin'}\n",
    "        self.country_of_origin = df_country_of_origin\n",
    "\n",
    "        # Citizenship\n",
    "        df_citizenship = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_population_by_citizenship.pkl')\n",
    "        df_citizenship.attrs = {'name': 'Citizenship'}\n",
    "        self.citizenship = df_citizenship\n",
    "\n",
    "        # Marital status\n",
    "        df_marital_status = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_population_by_marital_status.pkl')\n",
    "        df_marital_status.attrs = {'name': 'Marital status'}\n",
    "        self.marital_status = df_marital_status\n",
    "\n",
    "        # Family type and children\n",
    "        df_family_type_and_children = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_population_by_family_type_and_number_of_chidren.pkl')\n",
    "        df_family_type_and_children.attrs = {\n",
    "            'name': 'Family type and children'}\n",
    "        self.family_type_and_children = df_family_type_and_children\n",
    "\n",
    "        # Income\n",
    "        df_income = pd.read_pickle(path_data_clean_root / 'cph_income.pkl')\n",
    "        df_income.attrs = {'name': 'Income'}\n",
    "        self.income = df_income\n",
    "\n",
    "        # Life span\n",
    "        df_life_span = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_life_span.pkl')\n",
    "        df_life_span.attrs = {'name': 'Life span'}\n",
    "        self.life_span = df_life_span\n",
    "\n",
    "        # Population movement\n",
    "        df_population_movement = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_population_movement.pkl')\n",
    "        df_population_movement.attrs = {'name': 'Population movement'}\n",
    "        self.population_movement = df_population_movement\n",
    "\n",
    "        # Dwellings\n",
    "        df_dwellings = pd.read_pickle(\n",
    "            path_data_clean_root / 'cph_dwellings.pkl')\n",
    "        df_dwellings.attrs = {'name': 'Dwellings'}\n",
    "        self.dwellings = df_dwellings\n",
    "\n",
    "    # Gets dataframes with district information:\n",
    "    def get_dataframes_with_district(self):\n",
    "        return [df\n",
    "                for df in self.get_all_dataframes()\n",
    "                if 'District' in df.columns]\n",
    "\n",
    "    # Gets all the dataframes and returns them in a list.\n",
    "    def get_all_dataframes(self):\n",
    "        return list(get_obj_attributes(self).values())\n",
    "\n",
    "    # Gets the names of all columns in all datasets.\n",
    "    def get_all_column_names(self):\n",
    "        # Initialize the list of all columns from all the dataframes:\n",
    "        all_columns = list()\n",
    "\n",
    "        # Get all columns.\n",
    "        for df in self.get_all_dataframes():\n",
    "            all_columns += df.columns.to_list()\n",
    "\n",
    "        return list(sorted(set(all_columns)))\n",
    "\n",
    "    # Displays the dataframes with specified names.\n",
    "    def display_dataframes(self, names=None):\n",
    "        for attribute_name, df in get_obj_attributes(self).items():\n",
    "            if (names is None) or (df.attrs[\"name\"] in names):\n",
    "                printmd(f'\\n**{df.attrs[\"name\"]}**:')\n",
    "                display(df)\n",
    "\n",
    "    # Gets the names of the dataframes in the object.\n",
    "    def get_dataframe_names(self):\n",
    "        return [df.attrs['name'] for df in self.get_dataframes()]\n",
    "\n",
    "    # Displays the names of the dataframes in the object.\n",
    "    def display_dataframe_names(self):\n",
    "        # Display all the dataframes.\n",
    "        df_names = self.get_dataframe_names()\n",
    "        printmd(f'The dataframes in the object are:')\n",
    "        printmd(f'***{\"***, ***\".join(df_names)}***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:38.762977Z",
     "start_time": "2021-05-09T20:09:34.628Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A function that applies default formatting to an axes.\n",
    "def format_axes(axes: plt.Axes,\n",
    "                keep_box=False):\n",
    "    if not keep_box:\n",
    "        axes.spines['top'].set_color('white')\n",
    "        axes.spines['right'].set_color('white')\n",
    "\n",
    "    axes.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "# A function that applies default formatting to annotation\n",
    "# of an axes.\n",
    "def format_axes_annotation(axes: plt.Axes):\n",
    "    axes.xaxis.label.set_fontsize(14)\n",
    "    axes.yaxis.label.set_fontsize(14)\n",
    "    axes.title.set_fontsize(16)\n",
    "\n",
    "\n",
    "# A function for creating common x-label for the figure.\n",
    "def figure_x_label(figure: plt.Figure,\n",
    "                   label: str,\n",
    "                   y_position=0.04,\n",
    "                   font_size=16):\n",
    "    figure.text(0.5, y_position, label,\n",
    "                ha='center',\n",
    "                fontdict={'size': font_size})\n",
    "\n",
    "\n",
    "# A function for creating common y-label for the figure.\n",
    "def figure_y_label(figure: plt.Figure,\n",
    "                   label: str,\n",
    "                   x_position=0.04,\n",
    "                   font_size=16):\n",
    "    figure.text(x_position, 0.5, label,\n",
    "                va='center',\n",
    "                rotation='vertical',\n",
    "                fontdict={'size': font_size})\n",
    "\n",
    "\n",
    "# A function that draws a horizontal line across the entire axes.\n",
    "def draw_threshold(value: float,\n",
    "                   axes: plt.Axes,\n",
    "                   linewidth=1,\n",
    "                   linestyle='-',\n",
    "                   color=None,\n",
    "                   title=None):\n",
    "    \n",
    "    # Get axes limits and ranges.\n",
    "    x_min, x_max = axes.get_xlim()\n",
    "    x_range = x_max - x_min\n",
    "    y_min, y_max = axes.get_ylim()\n",
    "    y_range = y_max - y_min\n",
    "    \n",
    "    # Plot the threshold line.\n",
    "    axes.plot([x_min, x_max], [value, value],\n",
    "              linewidth=1,\n",
    "              linestyle='-',\n",
    "              color=color)\n",
    "    \n",
    "    # Write a title above the threshold line\n",
    "    if title is not None:\n",
    "        axes.text(x_min + 0.01 * x_range,\n",
    "                  value + 0.02 * y_range,\n",
    "                  title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataframe functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T20:09:38.764972Z",
     "start_time": "2021-05-09T20:09:34.632Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A function that gets column names of a dataframe.\n",
    "def get_df_columns(df, exclude=None):\n",
    "    # If columns to be excluded have not been defined,\n",
    "    # represent it as an empty list.\n",
    "    if exclude is None:\n",
    "        exclude = list()\n",
    "\n",
    "    # If the columns to be excluded are not specified using a list\n",
    "    # or a tuple, represent them as a list.\n",
    "    elif not isinstance(exclude, (list, tuple)):\n",
    "        exclude = [exclude]\n",
    "\n",
    "    # Return all column names except the ones to exclude.\n",
    "    return [column for column in df.columns.to_list()\n",
    "            if column not in exclude]\n",
    "\n",
    "\n",
    "# A function that resets the names of indices\n",
    "def reset_df_index_names(df):\n",
    "    return (\n",
    "        df\n",
    "        .rename_axis(['' for level in range(df.columns.nlevels)],\n",
    "                     axis=\"columns\")\n",
    "        .rename_axis(['' for level in range(df.index.nlevels)],\n",
    "                     axis=\"rows\")\n",
    "    )\n",
    "\n",
    "\n",
    "# A function for balancing a dataframe so that the number of rows\n",
    "# containing each value present in the designated column will be the same.\n",
    "def balance_dataframe(df: pd.DataFrame, column_name):\n",
    "    # Get the number of crimes for the least frequent crime.\n",
    "    lowest_frequency = df['Category'].value_counts().min()\n",
    "\n",
    "    # Create an empty dataframe for storing the balanced data\n",
    "    df_balanced = pd.DataFrame()\n",
    "\n",
    "    # For each value in column, randomly choose the number of samples\n",
    "    # that corresponds to the least frequent value in the column.\n",
    "    for value in df[column_name].unique():\n",
    "        df_balanced = df_balanced.append(\n",
    "            df\n",
    "            .loc[df[column_name] == value]\n",
    "            .sample(lowest_frequency)\n",
    "        )\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "\n",
    "# A function that evaluates a dictionary of models on data from\n",
    "# a pandas dataframe.\n",
    "def evaluate_models(models: dict,\n",
    "                    df: pd.DataFrame,\n",
    "                    predictor_labels: list,\n",
    "                    target_label: str,\n",
    "                    test_size=0.33):\n",
    "\n",
    "    # Get the dataset.\n",
    "    X = df.loc[:, predictor_labels].values\n",
    "    y = df.loc[:, target_label].values\n",
    "\n",
    "    # Split the dataset into a test and training set.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=32)\n",
    "\n",
    "    # Fit the models to the data.\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        # Print the name of the model.\n",
    "        printmd(f'*__{model_name}:__*')\n",
    "\n",
    "        # Train the model on the training set.\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Get the predictions on the test set.\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Print the classification report.\n",
    "        print(classification_report(y_test, predictions,\n",
    "                                    zero_division=0,\n",
    "                                    digits=4))\n",
    "\n",
    "\n",
    "# A function that sorts the columns in alphabethical order\n",
    "# and puts the user-chosen columns first\n",
    "def df_sort_columns(df: pd.DataFrame,\n",
    "                    first_columns=['Year',\n",
    "                                   'Quarter',\n",
    "                                   'District',\n",
    "                                   'District type',\n",
    "                                   'Sex',\n",
    "                                   'Age']):\n",
    "\n",
    "    # Define a function that moves the chosen element to the\n",
    "    # front of the list.\n",
    "    def move_to_front(element, list_):\n",
    "        if element in list_:\n",
    "            list_.insert(0, list_.pop(list_.index(element)))\n",
    "\n",
    "    # Make sure that the columns that are to be put in front\n",
    "    # are represented as a list.\n",
    "    if first_columns is None:\n",
    "        first_columns = list()\n",
    "\n",
    "    # Sort the columns in alphabetical order.\n",
    "    sorted_columns = list(df.columns)\n",
    "    sorted_columns.sort()\n",
    "\n",
    "    # Move the user-chosen columns to the front.\n",
    "    for column in first_columns[::-1]:\n",
    "        move_to_front(column, sorted_columns)\n",
    "\n",
    "    # Assign the ordered columns to the dataframe.\n",
    "    df = df[sorted_columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# A function that creates a new column representing data in 'value_columns'\n",
    "# for every unique value in 'category_columns'.\n",
    "def df_create_column_for_each_unique_value(df,\n",
    "                                           category_columns,\n",
    "                                           value_columns,\n",
    "                                           aggfunc='first'):\n",
    "\n",
    "    # Always represent category and value columns as a list or tuple.\n",
    "    if not isinstance(category_columns, (list, tuple)):\n",
    "        category_columns = [category_columns]\n",
    "\n",
    "    if not isinstance(value_columns, (list, tuple)):\n",
    "        value_columns = [value_columns]\n",
    "\n",
    "    # Create a colum order for grouping so that all the value columns\n",
    "    # come last and category columns second last. We leave out 1\n",
    "    # value column for the result\n",
    "    cat_and_value_columns = category_columns + value_columns\n",
    "    column_order = (\n",
    "        get_df_columns(df, exclude=cat_and_value_columns)\n",
    "        + cat_and_value_columns[:-1]\n",
    "    )\n",
    "\n",
    "    # Create columns from unique values by grouping and unstacking.\n",
    "    df = (\n",
    "        df\n",
    "        .groupby(column_order)\n",
    "        .first()\n",
    "        .unstack(list(np.arange(-len(cat_and_value_columns) + 1,\n",
    "                                0)))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Delete the names of the index levels\n",
    "    df = df.rename_axis(['' for level in range(df.columns.nlevels)],\n",
    "                        axis=\"columns\")\n",
    "    return df\n",
    "\n",
    "# OLD IMPLEMENTATION\n",
    "#     return (\n",
    "#         df\n",
    "#         .pivot_table(values=value_columns,\n",
    "#                      index=get_df_columns(df,\n",
    "#                                           exclude=category_columns + value_columns),\n",
    "#                      columns=category_columns,\n",
    "#                      aggfunc='first')\n",
    "#         .reset_index()\n",
    "#         .rename_axis(('', ''), axis=\"columns\")\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:04.754649Z",
     "start_time": "2021-05-10T13:22:04.483678Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fccdc68de5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# A function that cleans the data about copenhagen district\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mclean_districts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Continue only if the dataframe contains the column: \"district\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a function that loads a dataframe from\n",
    "# kk.statistikbank.dk\n",
    "def load_cph_df(path_csv):\n",
    "    return pd.read_csv(path_csv,\n",
    "                       sep='\\t',\n",
    "                       skiprows=0,\n",
    "                       encoding='windows-1252')\n",
    "\n",
    "\n",
    "\n",
    "# A function that sets data types for all columns.\n",
    "def set_data_types(df, columns_int, columns_str):\n",
    "\n",
    "    # We want to use only ins, strings, and floats.\n",
    "    # Therefore, specifying float columns is superficial.\n",
    "    columns_float = get_df_columns(df,\n",
    "                                   exclude=columns_int + columns_str)\n",
    "\n",
    "    # Set the data types.\n",
    "    df[columns_int] = df[columns_int].astype('Int64')\n",
    "    df[columns_str] = df[columns_str].astype(str)\n",
    "    df[columns_float] = df[columns_float].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# A function that loads a dataframe from multiple files.\n",
    "def load_split_dataframe(paths_csv):\n",
    "\n",
    "    # Load the first two dataframes.\n",
    "    df_1 = load_cph_df(paths_csv[0])\n",
    "    df_2 = load_cph_df(paths_csv[1])\n",
    "\n",
    "    # Extract common columns.\n",
    "    common_columns = list(set(df_1.columns)\n",
    "                          & set(df_2.columns))\n",
    "\n",
    "    # Load the whole dataframe.\n",
    "    for idx, path_csv in enumerate(paths_csv):\n",
    "        # Merge the dataframes.\n",
    "        if idx == 0:\n",
    "            df = load_cph_df(path_csv)\n",
    "        else:\n",
    "            df = df.merge(load_cph_df(path_csv),\n",
    "                          left_on=common_columns,\n",
    "                          right_on=common_columns)\n",
    "\n",
    "    # Return the merged dataframe.\n",
    "    return df\n",
    "\n",
    "# A function that cleans the data about copenhagen district\n",
    "def clean_districts(df: pd.DataFrame):\n",
    "\n",
    "    # Continue only if the dataframe contains the column: \"district\"\n",
    "    if 'district' not in df.columns:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Define the dame of the column containing info about districts.\n",
    "    district_column_name = 'district'\n",
    "\n",
    "    # Extract the district names.\n",
    "    districts = df[district_column_name]\n",
    "\n",
    "    # Initialize the list for storing district types.\n",
    "    district_types = list()\n",
    "\n",
    "    # Define valid districts.\n",
    "    valid_districts = ['Indre By', 'Østerbro', 'Nørrebro', 'Vesterbro/Kongens Enghave', 'Valby',\n",
    "                       'Vanløse', 'Brønshøj-Husum', 'Bispebjerg', 'Amager Øst', 'Amager Vest']\n",
    "\n",
    "    # Define valid districts.\n",
    "    valid_polling_areas = ['1. Østerbro', '1. Øst', '1. Nord', '1. Syd', '1. Vest', '1. Nordvest',\n",
    "                           '2. Sundbyvester', '2. Nord', '2. Syd', '2. Øst', '2. Vest', '3. Indre By',\n",
    "                           '3. Nord', '3. Syd', '3. Øst',\n",
    "                           '4. Sundbyøster', '4. Nord', '4. Syd', '4. Øst',\n",
    "                           '5. Nørrebro', '5. Nord', '5. Nørrebrohallen',\n",
    "                           '5. Syd', '5. Øst', '5. Vest', '5. Nordvest',\n",
    "                           '6. Bispebjerg', '6. Vest', '6. Nord', '6. Øst', '6. Syd',\n",
    "                           '7. Brønshøj', '7. Nord', '7. Syd', '7. Øst', '7. Vest',\n",
    "                           '7. Nordvest', '7. Katrinedal', '7. Kirkebjerg', '7. Vanløse',\n",
    "                           '8. Valby', '8. Nord', '8. Syd', '8. Vest', '8. Sydøst', '8. Midt',\n",
    "                           '9. Vesterbro', '9. Nord', '9. Syd',\n",
    "                           '9. Øst', '9. Vest', '9. Midt', '9. Sydhavn']\n",
    "\n",
    "    # Assign type to each district.\n",
    "    for district in districts:\n",
    "        if (('District' in district) | (district in valid_districts)):\n",
    "            district_types.append('District')\n",
    "\n",
    "        elif (('Polling area' in district) | (district in valid_polling_areas)):\n",
    "            district_types.append('Polling area')\n",
    "\n",
    "        elif 'Copenhagen total' in district:\n",
    "            district_types.append('Entire Copenhagen')\n",
    "\n",
    "        else:\n",
    "            district_types.append('Unknown')\n",
    "\n",
    "    # Insert the column \"district type\" next to the district column.\n",
    "    idx_district_column = df.columns.to_list().index(district_column_name)\n",
    "    df.insert(idx_district_column + 1, 'district type', district_types)\n",
    "\n",
    "    # Clean the names in the district - column.\n",
    "    for token in ['District -', 'Polling area -']:\n",
    "        df[district_column_name] = (\n",
    "            df[district_column_name]\n",
    "            .str.replace(token, '')\n",
    "            .str.strip()\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# A function that cleans all the information about the time in the\n",
    "# dataframes for Copenhagen.\n",
    "def clean_years(df: pd.DataFrame,\n",
    "                non_year_columns=None,\n",
    "                value_name='Value'):\n",
    "\n",
    "    if non_year_columns is not None:\n",
    "        # If \"non_year_columns\" is an integer, regard the first n\n",
    "        # columns represented by the integer as non-year columns\n",
    "        if isinstance(non_year_columns, int):\n",
    "            non_year_columns = df.columns[:non_year_columns]\n",
    "    else:\n",
    "        non_year_columns = [column for column in df.columns.to_list()\n",
    "                            if column[0] not in ['1', '2']]\n",
    "\n",
    "    # Create a row for each Year and Quarter.\n",
    "    df = df.melt(\n",
    "        id_vars=non_year_columns,\n",
    "        var_name=\"Time\",\n",
    "        value_name=value_name\n",
    "    )\n",
    "\n",
    "    # If the time is represented by a year and a quarter,\n",
    "    # create columns \"Year\" and \"Quarter\" from the column \"Time\".\n",
    "    if 'Q' in df.loc[0, 'Time']:\n",
    "        df[['Year', 'Quarter']] = (\n",
    "            df\n",
    "            .pop('Time').str.split('Q', 2, expand=True)\n",
    "            .astype(int)\n",
    "        )\n",
    "\n",
    "    # If year is presented as \"XXXX:YYYY\", take the second value.\n",
    "    elif ':' in df.loc[0, 'Time']:\n",
    "        df['Year'] = (\n",
    "            df\n",
    "            .pop('Time')\n",
    "            .str.split(':').str[-1]\n",
    "            .astype(int)\n",
    "        )\n",
    "\n",
    "    # Otherwise, transform the year into an integer\n",
    "    else:\n",
    "        df['Year'] = df.pop('Time').astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# A fuction that removes all other quarters of the year than last.\n",
    "def choose_latest_quarter(df: pd.DataFrame, value_name):\n",
    "    # Run only if the dataframe has a column \"Quarter\"\n",
    "    if 'Quarter' not in df.columns:\n",
    "        return df\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .sort_values(by=['Year', 'Quarter'])\n",
    "        .groupby([column for column in df.columns\n",
    "                  if column not in ['Quarter', value_name]],\n",
    "                 as_index=False)\n",
    "        .last()\n",
    "    )\n",
    "\n",
    "\n",
    "# A function that perfoms standard cleaning of a dataframe\n",
    "# from kk.statistikbank.dk\n",
    "def clean_cph_dataframe(df, value_name='Value', df_name=''):\n",
    "    # Clean district information.\n",
    "    df = clean_districts(df)\n",
    "\n",
    "    # Clean time information.\n",
    "    df = clean_years(df, value_name=value_name)\n",
    "\n",
    "    # Capitalize column names.\n",
    "    df.columns = [column.capitalize() for column in df.columns]\n",
    "\n",
    "    # Standardize age intervals\n",
    "    df_standardize_age(df, value_name)\n",
    "\n",
    "    # Choose only the last available quarter of the year.\n",
    "    df = choose_latest_quarter(df, value_name)  \n",
    "    \n",
    "    # Order the columns.\n",
    "    df = df_sort_columns(df)\n",
    "    \n",
    "    # Name the dataframe.\n",
    "    df.name = df_name\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# A function that displays all basic stats about the dataframe.\n",
    "def show_stats(df):\n",
    "    # Show data types.\n",
    "    display(df.dtypes.to_frame('Data types'))\n",
    "\n",
    "    # Show missing values.\n",
    "    display(\n",
    "        df.isna()\n",
    "        .sum()\n",
    "        .to_frame('Number of missing values')\n",
    "    )\n",
    "\n",
    "    # Describe values in columns.\n",
    "    display(df.describe(include='all'))\n",
    "\n",
    "\n",
    "# A function that unifies age intervals in the databases from\n",
    "# from Københavns Kommune:\n",
    "def df_standardize_age(df: pd.DataFrame, sum_column):\n",
    "\n",
    "    # Run only if the dataframe has a column \"Age\"\n",
    "    if 'Age' not in df.columns:\n",
    "        return df\n",
    "\n",
    "    # Use 10-year intervals for age: Create the mapping.\n",
    "    mapping_age = dict()\n",
    "    for interval_min in range(0, 90, 10):\n",
    "        map_from_low = f'{interval_min}-{interval_min + 4} years'\n",
    "        map_from_high = f'{interval_min + 5}-{interval_min + 9} years'\n",
    "        map_from_10_years = f'{interval_min}-{interval_min + 9} years'\n",
    "        map_to = f'{interval_min}-{interval_min + 9} years'\n",
    "        \n",
    "        mapping_age[map_from_low] = map_to\n",
    "        mapping_age[map_from_high] = map_to\n",
    "        mapping_age[map_from_10_years] = map_to\n",
    "    \n",
    "    # Define the mapping for all the possible versions of the 90+ age.\n",
    "    over_90 = '>= 90 years'\n",
    "    mapping_age['90-99 years'] = over_90\n",
    "    mapping_age['90-99 + years'] = over_90\n",
    "    mapping_age['95-99 years'] = over_90\n",
    "    mapping_age['90-94 years'] = over_90\n",
    "    mapping_age['100 years and over'] = over_90\n",
    "    mapping_age['95+years'] = over_90\n",
    "\n",
    "    # Apply the mapping to the column \"Age\".\n",
    "    df['Age'] = df['Age'].map(mapping_age)\n",
    "\n",
    "    # Sum the values in the new bins. First, get the names\n",
    "    # of all the columns that are NOT the column which will summed up.\n",
    "    non_sum_columns = [column for column in df.columns\n",
    "                       if column != sum_column]\n",
    "\n",
    "    # Sum the values together in the age bins.\n",
    "    df[sum_column] = (\n",
    "        df\n",
    "        .groupby(non_sum_columns)\n",
    "        .transform('sum')\n",
    "    )\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df.drop_duplicates(ignore_index=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "PyCharm (Exercises)",
   "language": "python",
   "name": "pycharm-f0629d26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "440.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
